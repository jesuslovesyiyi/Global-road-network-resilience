{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "import osmnx as ox\n",
    "import networkx as nx\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import numpy as np\n",
    "import shapely\n",
    "import pickle\n",
    "\n",
    "import shutil\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import warnings; warnings.simplefilter('ignore')\n",
    "\n",
    "pd.options.display.max_columns = None\n",
    "pd.options.display.max_rows = 30\n",
    "np.set_printoptions(threshold=sys.maxsize)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dry condition routing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dry_mean_traveltime_df = pd.DataFrame(columns=['net_id','dry_mean_time_s'], index=range(4190))\n",
    "counter = 0\n",
    "\n",
    "for graph_file in tqdm(os.listdir('L:yiyi/graphs_cov_no_res3/')):\n",
    "    \n",
    "    G1 =  pickle.load(open('L:yiyi/graphs_cov_no_res3/'+graph_file, 'rb'))\n",
    "    net_id = graph_file[15:][:-3]\n",
    "    \n",
    "    try:\n",
    "        # Add speed and travel_time on each graph edge\n",
    "        G1_speed = ox.speed.add_edge_speeds(G1)\n",
    "        G1_speed_time = ox.speed.add_edge_travel_times(G1_speed)\n",
    "\n",
    "        # Load OD probability list\n",
    "        OD_probability_1 = pd.read_csv(r'L:\\yiyi\\ODpts_propbability\\n_4229_bnd_' + str(int(net_id)-1) + '.txt')\n",
    "        pt_id_lst = list(OD_probability_1['pointid'])\n",
    "        pt_prob_lst = list(OD_probability_1['grid_code'])\n",
    "\n",
    "        OD_df = pd.DataFrame(columns=['index',\n",
    "                                      'O_node_id',\n",
    "                                      'D_node_id',\n",
    "                                      'O_lat',\n",
    "                                      'O_lon',\n",
    "                                      'D_lat',\n",
    "                                      'D_lon',\n",
    "                                      'OD_route',\n",
    "                                      'OD_route_length_m',\n",
    "                                      'OD_route_time_s'])\n",
    "        index = 0\n",
    "        epsilon = float('inf')\n",
    "        travel_time_lst = []\n",
    "\n",
    "        while epsilon > 0.01:\n",
    "\n",
    "            #Sample a point based on probability\n",
    "            sample_O_pt = random.choices(pt_id_lst, pt_prob_lst)[0]\n",
    "            sample_D_pt = random.choices(pt_id_lst, pt_prob_lst)[0]\n",
    "            while sample_O_pt == sample_D_pt:\n",
    "                sample_D_pt = random.choices(pt_id_lst, pt_prob_lst)[0]\n",
    "\n",
    "            # O\n",
    "            sample_O_lat = OD_probability_1.loc[OD_probability_1['pointid'] == sample_O_pt, 'POINT_X'].iloc[0]\n",
    "            sample_O_lon = OD_probability_1.loc[OD_probability_1['pointid'] == sample_O_pt, 'POINT_Y'].iloc[0]\n",
    "            # D\n",
    "            sample_D_lat = OD_probability_1.loc[OD_probability_1['pointid'] == sample_D_pt, 'POINT_X'].iloc[0]\n",
    "            sample_D_lon = OD_probability_1.loc[OD_probability_1['pointid'] == sample_D_pt, 'POINT_Y'].iloc[0]\n",
    "\n",
    "            O_node_id = ox.distance.get_nearest_node(G1, (sample_O_lon, sample_O_lat), method='haversine') # lon, lat\n",
    "            D_node_id = ox.distance.get_nearest_node(G1, (sample_D_lon, sample_D_lat), method='haversine')\n",
    "\n",
    "            # Routing\n",
    "            try:\n",
    "                OD_route = nx.shortest_path(G1_speed_time, O_node_id, D_node_id, weight='travel_time')\n",
    "            except:\n",
    "                continue\n",
    "\n",
    "            OD_route_length = sum(ox.utils_graph.get_route_edge_attributes(G1_speed_time, OD_route, 'length')) # meters\n",
    "            OD_route_time =sum(ox.utils_graph.get_route_edge_attributes(G1_speed_time, OD_route, 'travel_time')) # seconds\n",
    "\n",
    "\n",
    "            OD_df.loc[index] = [index+1, O_node_id, D_node_id, sample_O_lat, sample_O_lon, sample_D_lat, sample_D_lon,\n",
    "                            OD_route, OD_route_length, OD_route_time]\n",
    "\n",
    "            travel_time_lst.append(OD_route_time)\n",
    "\n",
    "            if len(travel_time_lst) == 1:\n",
    "                epsilon = float('inf')\n",
    "            else:\n",
    "                epsilon = abs(np.mean(travel_time_lst) - np.mean(travel_time_lst[:-1]))\n",
    "\n",
    "            index += 1\n",
    "            OD_df.to_csv('L:/yiyi/dry_OD_routing/G_' + net_id + '_dry.csv')\n",
    "            \n",
    "        dry_mean_traveltime_df.at[counter, 'net_id'] = net_id\n",
    "        dry_mean_traveltime_df.at[counter, 'dry_mean_time_s'] = np.mean(travel_time_lst)\n",
    "    \n",
    "        counter += 1\n",
    "    except:\n",
    "        print(net_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wet condition routing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare graphs to process\n",
    "RP_lst = [5, 10, 20, 50, 75, 100, 200, 250, 500, 1000]\n",
    "flood_graphs_lst = []\n",
    "for rp in RP_lst:\n",
    "    one_lst = []\n",
    "    for file in os.listdir('L:/yiyi/2576_disrupted_graphs_30mm/FUP_' + str(rp) + '/'):\n",
    "        net_id = int(file[2:][:(-18) - len(str(rp))])\n",
    "        one_lst.append(net_id)\n",
    "    flood_graphs_lst.append(one_lst)\n",
    "    \n",
    "common_graphs = set(flood_graphs_lst[0])\n",
    "for lst in flood_graphs_lst[1:]:\n",
    "    common_graphs.intersection_update(lst)\n",
    "print('Number of common graphs:',len(common_graphs))\n",
    "\n",
    "RP_lst = [5, 10, 20, 50, 75, 100, 200, 250, 500, 1000]\n",
    "\n",
    "dry_routing_dir = 'L:/yiyi/dry_OD_routing/'\n",
    "\n",
    "# for file in os.listdir(dry_routing_dir):\n",
    "for net in tqdm(common_graphs):\n",
    "    dry_OD_df = pd.read_csv(dry_routing_dir + 'G_' + str(net) + '_dry.csv', index_col=0)\n",
    "    net_id = net\n",
    "    wet_OD_df = dry_OD_df.copy()\n",
    "    # Initiate flooded columns\n",
    "    for rp in RP_lst:\n",
    "        wet_OD_df['OD_route_FUP_' + str(rp)] = None\n",
    "        wet_OD_df['OD_length_FUP_' + str(rp)] = 0\n",
    "        wet_OD_df['OD_time_FUP_' + str(rp)] = 0\n",
    "    for rp in RP_lst:\n",
    "        graph_disrupted = pickle.load(open('L:/yiyi/2576_disrupted_graphs_30mm/FUP_'+ str(rp) + '/G_' + \n",
    "                                               str(net_id) + '_disrupted_FUP_' + str(rp) + '.pk', 'rb'))\n",
    "        print(rp)\n",
    "        for row_idx in range(wet_OD_df.shape[0]):\n",
    "            O_node_id = wet_OD_df.iloc[row_idx]['O_node_id']\n",
    "            D_node_id = wet_OD_df.iloc[row_idx]['D_node_id']\n",
    "            try:\n",
    "                wet_OD_route = nx.shortest_path(graph_disrupted, O_node_id, D_node_id, weight='travel_time')\n",
    "                wet_OD_route_length = sum(ox.utils_graph.get_route_edge_attributes(graph_disrupted, wet_OD_route, 'length')) # meters\n",
    "                wet_OD_route_time =sum(ox.utils_graph.get_route_edge_attributes(graph_disrupted, wet_OD_route, 'travel_time')) # seconds\n",
    "\n",
    "                wet_OD_df.at[row_idx, 'OD_route_FUP_' + str(rp)] = wet_OD_route\n",
    "                wet_OD_df.at[row_idx, 'OD_length_FUP_' + str(rp)] = wet_OD_route_length\n",
    "                wet_OD_df.at[row_idx, 'OD_time_FUP_' + str(rp)] = wet_OD_route_time\n",
    "                \n",
    "            except:\n",
    "                continue\n",
    "    wet_OD_df.to_csv('L:yiyi/2576_dry_wet_OD_routing/G_' + str(net) + '_dry_wet_routing.csv')"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
